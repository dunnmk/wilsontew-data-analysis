---
title: "3C Summary CSV Aggregation and QC"
output:
  html_document:
    theme: bootstrap
    toc: true
    toc_depth: 3
---
This R Markdown document reads, combines, and summarizes multiple
`_summary.csv` files.
***
## 0. Packages

This section loads the packages used for import, manipulation, and plotting.

- `tidyverse` provides `dplyr`, `readr`, `purrr`, `stringr`, and `ggplot2`.
```{r setup, message=FALSE}
library(tidyverse)

# Make plots larger and labels more legible throughout the report
knitr::opts_chunk$set(
  fig.width = 16,
  fig.height = 8,
  dpi = 200,
  out.width = "100%",
  fig.align = "center"
)

# Ensure rmarkdown can find Pandoc.
# On Windows, Quarto bundles pandoc in: <quarto>/bin/tools/pandoc.exe.
if (!nzchar(Sys.which("pandoc"))) {
  quarto_exe <- Sys.which("quarto")
  if (nzchar(quarto_exe)) {
    quarto_tools <- normalizePath(
      file.path(dirname(quarto_exe), "tools"),
      winslash = "/",
      mustWork = FALSE
    )
    if (dir.exists(quarto_tools)) {
      Sys.setenv(RSTUDIO_PANDOC = quarto_tools)
    }
  }
}

# ---- Report-wide definitions (modeled after MD_PD_Analysis) ----

# Column name mapping (edit these if your input table uses different headers)
COL_BATCH <- "batch"
COL_TIME_POINT <- "time_point"
COL_DSB <- "DSB"
COL_ALLELE <- "allele"
COL_COMBO <- "combo"
COL_CIS_TRANS <- "cis_trans"
COL_REPEAT <- "repeat"
COL_COUNT <- "count"

# Derived column names produced in this report
COL_COUNT_SPIKE_SCALED <- "count_spike_scaled"
COL_COUNT_NORM <- "count_norm"

# Canonical 4-combo cis/trans definitions used throughout this report
combos_4 <- c("A_to_B", "C_to_D", "A_to_D", "C_to_B")
cis_combos <- c("A_to_B", "C_to_D")
trans_combos <- c("A_to_D", "C_to_B")

# Controls
# Guideline #2: NO_CUT control is used to show baseline growth in media.
# Guideline #3: 1% spike-in control is used to scale proportions across batch × time_point.
SPIKEIN_ALLELE <- "CHRXV_L18_1PERCENT_CONTROL"
NOCUT_ALLELE <- "NO_CUT"
CONTROL_ALLELES <- c(SPIKEIN_ALLELE, NOCUT_ALLELE)

# Summarize over the canonical 4 combos, and compute cis/trans from combos.
summarize_combo4_counts_pct <- function(dat,
                                       count_col = "count",
                                       group_cols = c("batch", "time_point", "DSB"),
                                       combo_col = "combo") {
  dat %>%
    filter(.data[[combo_col]] %in% combos_4) %>%
    group_by(across(all_of(group_cols))) %>%
    summarise(
      Total_Counts = sum(.data[[count_col]], na.rm = TRUE),
      Cis_Counts = sum(.data[[count_col]][.data[[combo_col]] %in% cis_combos], na.rm = TRUE),
      Trans_Counts = sum(.data[[count_col]][.data[[combo_col]] %in% trans_combos], na.rm = TRUE),
      A_to_B_Counts = sum(.data[[count_col]][.data[[combo_col]] == "A_to_B"], na.rm = TRUE),
      C_to_D_Counts = sum(.data[[count_col]][.data[[combo_col]] == "C_to_D"], na.rm = TRUE),
      A_to_D_Counts = sum(.data[[count_col]][.data[[combo_col]] == "A_to_D"], na.rm = TRUE),
      C_to_B_Counts = sum(.data[[count_col]][.data[[combo_col]] == "C_to_B"], na.rm = TRUE),
      Percent_Cis = if_else(Total_Counts > 0, 100 * Cis_Counts / Total_Counts, NA_real_),
      Percent_Trans = if_else(Total_Counts > 0, 100 * Trans_Counts / Total_Counts, NA_real_),
      Percent_A_to_B = if_else(Total_Counts > 0, 100 * A_to_B_Counts / Total_Counts, NA_real_),
      Percent_C_to_D = if_else(Total_Counts > 0, 100 * C_to_D_Counts / Total_Counts, NA_real_),
      Percent_A_to_D = if_else(Total_Counts > 0, 100 * A_to_D_Counts / Total_Counts, NA_real_),
      Percent_C_to_B = if_else(Total_Counts > 0, 100 * C_to_B_Counts / Total_Counts, NA_real_),
      .groups = "drop"
    )
}

# ---- Normalization helpers for plotting (A/(A+B)) ----
# These match the plot style used in MD_PD_Analysis.
#
#   %CIS   = CIS / (CIS + TRANS)
#   %TRANS = TRANS / (CIS + TRANS)
#   %INTACT = INTACT / (INTACT + SSA)
#   %SSA    = SSA / (INTACT + SSA)

ratio_ab <- function(a, b) {
  if_else((a + b) > 0, a / (a + b), NA_real_)
}

summarize_cis_trans_ab <- function(dat,
                                  count_col = COL_COUNT_NORM,
                                  group_cols = c(COL_BATCH, COL_TIME_POINT, COL_DSB)) {
  dat %>%
    filter(.data[[COL_COMBO]] %in% combos_4) %>%
    group_by(across(all_of(group_cols))) %>%
    summarise(
      Cis_Counts = sum(.data[[count_col]][.data[[COL_CIS_TRANS]] == "CIS"], na.rm = TRUE),
      Trans_Counts = sum(.data[[count_col]][.data[[COL_CIS_TRANS]] == "TRANS"], na.rm = TRUE),
      CisTrans_Total = Cis_Counts + Trans_Counts,
      Fraction_Cis = ratio_ab(Cis_Counts, Trans_Counts),
      Fraction_Trans = ratio_ab(Trans_Counts, Cis_Counts),
      Percent_Cis = 100 * Fraction_Cis,
      Percent_Trans = 100 * Fraction_Trans,
      .groups = "drop"
    )
}

summarize_intact_ssa_ab <- function(dat,
                                   count_col = COL_COUNT_NORM,
                                   group_cols = c(COL_BATCH, COL_TIME_POINT, COL_DSB)) {
  dat %>%
    filter(.data[[COL_COMBO]] %in% combos_4) %>%
    group_by(across(all_of(group_cols))) %>%
    summarise(
      Intact_Counts = sum(
        .data[[count_col]][stringr::str_to_upper(as.character(.data[[COL_REPEAT]])) == "INTACT"],
        na.rm = TRUE
      ),
      SSA_Counts = sum(
        .data[[count_col]][stringr::str_to_upper(as.character(.data[[COL_REPEAT]])) == "SSA"],
        na.rm = TRUE
      ),
      IntactSSA_Total = Intact_Counts + SSA_Counts,
      Fraction_Intact = ratio_ab(Intact_Counts, SSA_Counts),
      Fraction_SSA = ratio_ab(SSA_Counts, Intact_Counts),
      Percent_Intact = 100 * Fraction_Intact,
      Percent_SSA = 100 * Fraction_SSA,
      .groups = "drop"
    )
}
```
***

## 1. Read and combine ALL CSVs

Reads all `_summary.csv` files from `folder` and combines them into a single master table `dat_raw`.

- `folder`: directory containing summary CSVs
- `files`: all matching file paths
- `raw_list`: list of per-file data frames
- `dat_raw`: combined data frame
```{r import-csv}
folder <- "C:\\Users\\dunnmk\\University of Michigan Dropbox\\MED-WILSONTELAB\\wilsontelab box\\Common\\Projects\\Yeast Aim 3\\3C Sequencing Data\\3C_summary"
files  <- list.files(folder, pattern = "_summary\\.csv$", full.names = TRUE)
raw_list <- lapply(files, read_csv)
dat_raw <- bind_rows(raw_list)

# NOTE: do not modify the imported raw table; use a working copy for all downstream computations.
dat <- dat_raw %>%
  mutate(!!COL_BATCH := factor(.data[[COL_BATCH]], levels = sort(unique(.data[[COL_BATCH]])))) %>%
  mutate(
    !!COL_ALLELE := as.character(.data[[COL_ALLELE]]),
    !!COL_COMBO := as.character(.data[[COL_COMBO]]),
    !!COL_CIS_TRANS := as.character(.data[[COL_CIS_TRANS]]),
    # Make time_point safe for filtering (handles numeric, factor, or strings like "T120")
    !!COL_TIME_POINT := readr::parse_number(as.character(.data[[COL_TIME_POINT]]))
  )

# ---- Guideline #1: this report includes only time points 0 and 120 ----
dat <- dat %>%
  filter(.data[[COL_TIME_POINT]] %in% c(0, 120))

# ---- Guideline #3: spike-in scaling (batch × time_point) ----
spike_totals <- dat %>%
  filter(.data[[COL_ALLELE]] == SPIKEIN_ALLELE, .data[[COL_COMBO]] %in% combos_4) %>%
  group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT)))) %>%
  summarise(SpikeIn_Counts = sum(.data[[COL_COUNT]], na.rm = TRUE), .groups = "drop")

spike_ref <- spike_totals %>%
  filter(SpikeIn_Counts > 0) %>%
  summarise(ref = median(SpikeIn_Counts, na.rm = TRUE)) %>%
  pull(ref)

if (length(spike_ref) == 0 || is.na(spike_ref)) {
  spike_ref <- NA_real_
}

spike_factors <- spike_totals %>%
  mutate(
    SpikeIn_Scale = if_else(!is.na(spike_ref) & SpikeIn_Counts > 0, spike_ref / SpikeIn_Counts, 1.0),
    SpikeIn_Flag = case_when(
      is.na(spike_ref) ~ "no_spike_reference",
      SpikeIn_Counts <= 0 ~ "missing_or_zero_spike",
      TRUE ~ "ok"
    )
  )

dat <- dat %>%
  left_join(
    spike_factors %>% select(all_of(c(COL_BATCH, COL_TIME_POINT)), SpikeIn_Scale, SpikeIn_Flag),
    by = c(COL_BATCH, COL_TIME_POINT)
  ) %>%
  mutate(
    SpikeIn_Scale = replace_na(SpikeIn_Scale, 1.0),
    SpikeIn_Flag = replace_na(SpikeIn_Flag, "missing_or_zero_spike"),
    !!COL_COUNT_SPIKE_SCALED := .data[[COL_COUNT]] * SpikeIn_Scale
  )

# ---- Guideline #2: NO_CUT baseline growth signal ----
nocut_denoms <- dat %>%
  filter(.data[[COL_ALLELE]] == NOCUT_ALLELE, .data[[COL_COMBO]] %in% combos_4) %>%
  group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT, COL_DSB, COL_COMBO, COL_REPEAT)))) %>%
  summarise(NoCut_Denom = sum(.data[[COL_COUNT_SPIKE_SCALED]], na.rm = TRUE), .groups = "drop")

dat <- dat %>%
  left_join(nocut_denoms, by = c(COL_BATCH, COL_TIME_POINT, COL_DSB, COL_COMBO, COL_REPEAT)) %>%
  mutate(
    # Doubly-normalized counts (optional for some plots): spike-in scaled, then normalized to matched NO_CUT denom.
    !!COL_COUNT_NORM := if_else(!is.na(NoCut_Denom) & NoCut_Denom > 0,
                               .data[[COL_COUNT_SPIKE_SCALED]] / NoCut_Denom,
                               NA_real_)
  )

# Biological rows only (exclude spike-in and NO_CUT controls from allele-level summaries)
dat_bio <- dat %>%
  filter(!(.data[[COL_ALLELE]] %in% CONTROL_ALLELES))

str(dat)
dat |> head(10) |> knitr::kable(caption = "Preview: combined `_summary.csv` rows used for analysis (first 10)")

# Quick QC: spike-in totals and applied scale factors
spike_factors %>%
  arrange(time_point, batch) %>%
  knitr::kable(caption = "Spike-in totals and scaling factors by batch × time_point")

nocut_denoms %>%
  arrange(time_point, batch, DSB, `repeat`, combo) %>%
  head(20) %>%
  knitr::kable(caption = "NO_CUT denominators (spike-scaled) by batch × time_point × DSB × repeat × combo (first 20)")

```
***

## 2. Aggregate counts and percentages


Purpose- Calculate percentages from aggregated counts

```{r aggregate-counts}
dat_agg_counts <- summarize_combo4_counts_pct(
  dat_bio,
  count_col = COL_COUNT_SPIKE_SCALED,
  group_cols = c(COL_BATCH, COL_TIME_POINT, COL_DSB),
  combo_col = COL_COMBO
)
str(dat_agg_counts)
dat_agg_counts |> head(10) |> knitr::kable(caption = "Aggregated counts + derived percentages by batch × time_point × DSB (first 10)")
```

The table above is now aggregated to batch × time_point × DSB.
***

## 2.5 Batch-level QC plots (counts + composition)

Purpose- Quick sanity-check plots *before* allele-level cis/trans normalization.

```{r batch-qc-plots, message=FALSE, warning=FALSE}
# Aggregate from the working analysis table
agg_qc <- summarize_combo4_counts_pct(
  dat_bio,
  count_col = COL_COUNT_SPIKE_SCALED,
  group_cols = c(COL_BATCH, COL_TIME_POINT, COL_DSB),
  combo_col = COL_COMBO
)

# From here on in QC, compute CIS/TRANS using ONLY the 4 combos of interest:
#   CIS   := A_to_B + C_to_D
#   TRANS := A_to_D + C_to_B
# and define percents relative to the total of these 4 combos.
#
# IMPORTANT: we intentionally DO NOT group by `DSB` here.
# In this dataset, `DSB` can include levels like "TRANS", and grouping by it
# will split CIS and TRANS into different facets and produce misleading 100% bars.
agg_qc_combo4 <- dat %>%
  group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT)))) %>%
  summarise(
    # NOTE: use na.rm=TRUE so a single NA doesn't turn the entire group into NA
    Total_All = sum(.data[[COL_COUNT_SPIKE_SCALED]], na.rm = TRUE),
    A_to_B = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "A_to_B"], na.rm = TRUE),
    C_to_D = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "C_to_D"], na.rm = TRUE),
    A_to_D = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "A_to_D"], na.rm = TRUE),
    C_to_B = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "C_to_B"], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Cis_Counts = A_to_B + C_to_D,
    Trans_Counts = A_to_D + C_to_B,
    Total_4Combos = Cis_Counts + Trans_Counts,
    Excluded_Counts = pmax(Total_All - Total_4Combos, 0),
    Percent_Cis = if_else(Total_4Combos > 0, 100 * Cis_Counts / Total_4Combos, NA_real_),
    Percent_Trans = if_else(Total_4Combos > 0, 100 * Trans_Counts / Total_4Combos, NA_real_),
    Percent_A_to_B_in_Cis = if_else(Cis_Counts > 0, 100 * A_to_B / Cis_Counts, NA_real_),
    Percent_C_to_D_in_Cis = if_else(Cis_Counts > 0, 100 * C_to_D / Cis_Counts, NA_real_),
    Percent_A_to_D_in_Trans = if_else(Trans_Counts > 0, 100 * A_to_D / Trans_Counts, NA_real_),
    Percent_C_to_B_in_Trans = if_else(Trans_Counts > 0, 100 * C_to_B / Trans_Counts, NA_real_)
  )

# Quick diagnostic table: if Excluded_Counts is large, then the 4-combo definition is omitting real counts.
agg_qc_combo4 %>%
  arrange(time_point, batch) %>%
  transmute(
    batch, time_point,
    Total_All,
    Total_4Combos,
    Excluded_Counts,
    Percent_Cis,
    Percent_Trans
  ) %>%
  head(20) %>%
  knitr::kable(caption = "QC (4-combo definition): totals vs excluded counts, plus CIS%/TRANS% (first 20 rows)")

# Formatting helpers (avoid extra package dependencies)
comma_label <- function(x) {
  ifelse(is.na(x), NA_character_, formatC(x, format = "f", digits = 0, big.mark = ","))
}

pct_label <- function(x, digits = 1) {
  ifelse(is.na(x), NA_character_, paste0(round(x, digits), "%"))
}

# 1) Total counts by batch
p_total_counts <- ggplot(agg_qc, aes(x = batch, y = Total_Counts, fill = DSB)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.75) +
  geom_text(
    aes(label = comma_label(Total_Counts)),
    position = position_dodge(width = 0.8),
    vjust = -0.25,
    size = 2.7
  ) +
  facet_wrap(~ time_point, scales = "free_y") +
  theme_bw() +
  labs(
    title = "Total counts by batch (faceted by time_point)",
    x = "Batch",
    y = "Total counts",
    fill = "DSB"
  )

if (nrow(agg_qc) > 0) {
  print(p_total_counts)
} else {
  message("[2.5 QC] agg_qc is empty; no total-count plot was produced.")
}

# 2) CIS-only counts by category within each batch (4-combo definition)
cis_counts_long <- agg_qc_combo4 %>%
  select(batch, time_point, Cis_Counts, A_to_B, C_to_D) %>%
  pivot_longer(
    cols = -c(batch, time_point),
    names_to = "Metric",
    values_to = "Counts"
  ) %>%
  mutate(
    Metric = factor(
      Metric,
      levels = c("Cis_Counts", "A_to_B", "C_to_D"),
      labels = c("CIS (total)", "A to B (cis)", "C to D (cis)")
    )
  )

p_cis_counts <- ggplot(cis_counts_long, aes(x = batch, y = Counts, fill = Metric)) +
  geom_col(position = position_dodge(width = 0.85), width = 0.8) +
  geom_text(
    aes(label = comma_label(Counts)),
    position = position_dodge(width = 0.85),
    vjust = -0.25,
    size = 2.4
  ) +
  facet_wrap(~ time_point, scales = "free_y") +
  theme_bw() +
  labs(
    title = "CIS counts by category per batch",
    x = "Batch",
    y = "Counts",
    fill = ""
  )

if (nrow(cis_counts_long) > 0) {
  print(p_cis_counts)
} else {
  message("[2.5 QC] cis_counts_long is empty; no CIS-count plot was produced.")
}

# 3) TRANS-only counts by category within each batch (4-combo definition)
trans_counts_long <- agg_qc_combo4 %>%
  select(batch, time_point, Trans_Counts, A_to_D, C_to_B) %>%
  pivot_longer(
    cols = -c(batch, time_point),
    names_to = "Metric",
    values_to = "Counts"
  ) %>%
  mutate(
    Metric = factor(
      Metric,
      levels = c("Trans_Counts", "A_to_D", "C_to_B"),
      labels = c("TRANS (total)", "A to D (trans)", "C to B (trans)")
    )
  )

p_trans_counts <- ggplot(trans_counts_long, aes(x = batch, y = Counts, fill = Metric)) +
  geom_col(position = position_dodge(width = 0.85), width = 0.8) +
  geom_text(
    aes(label = comma_label(Counts)),
    position = position_dodge(width = 0.85),
    vjust = -0.25,
    size = 2.4
  ) +
  facet_wrap(~ time_point, scales = "free_y") +
  theme_bw() +
  labs(
    title = "TRANS counts by category per batch",
    x = "Batch",
    y = "Counts",
    fill = ""
  )

if (nrow(trans_counts_long) > 0) {
  print(p_trans_counts)
} else {
  message("[2.5 QC] trans_counts_long is empty; no TRANS-count plot was produced.")
}

# 4) CIS vs TRANS percent for each batch (single plot; bars side-by-side)
# Percent_Cis/Percent_Trans are computed relative to TOTAL_4Combos.
pct_cis_trans_long <- agg_qc_combo4 %>%
  select(batch, time_point, Percent_Cis, Percent_Trans) %>%
  pivot_longer(
    cols = c(Percent_Cis, Percent_Trans),
    names_to = "Class",
    values_to = "Percent"
  ) %>%
  mutate(
    Class = recode(Class, Percent_Cis = "CIS", Percent_Trans = "TRANS"),
    Label = pct_label(Percent)
  )

p_pct_cis_trans <- ggplot(pct_cis_trans_long, aes(x = batch, y = Percent, fill = Class)) +
  geom_col(position = position_dodge(width = 0.85), width = 0.8) +
  geom_text(
    aes(label = Label),
    position = position_dodge(width = 0.85),
    vjust = -0.25,
    size = 3.2
  ) +
  facet_wrap(~ time_point) +
  scale_y_continuous(limits = c(0, 110)) +
  theme_bw() +
  labs(
    title = "QC: CIS vs TRANS percent per batch (within group)",
    x = "Batch",
    y = "% of total counts",
    fill = ""
  )

if (nrow(pct_cis_trans_long) > 0) {
  print(p_pct_cis_trans)
} else {
  message("[2.5 QC] pct_cis_trans_long is empty; no CIS/TRANS% plot was produced.")
}

# 5b) Percent TRANS per batch at T0 vs T120 (single plot; bars side-by-side)
pct_trans_time_compare <- agg_qc_combo4 %>%
  filter(time_point %in% c(0, 120)) %>%
  transmute(
    batch,
    time_point = factor(time_point, levels = c(0, 120), labels = c("T0", "T120")),
    Percent_Trans,
    Label = pct_label(Percent_Trans)
  )

p_pct_trans_t0_t120 <- ggplot(pct_trans_time_compare, aes(x = batch, y = Percent_Trans, fill = time_point)) +
  geom_col(position = position_dodge(width = 0.85), width = 0.8) +
  geom_text(
    aes(label = Label),
    position = position_dodge(width = 0.85),
    vjust = -0.25,
    size = 3.2
  ) +
  scale_y_continuous(limits = c(0, 110)) +
  theme_bw() +
  labs(
    title = "QC: TRANS% per batch (T0 vs T120)",
    x = "Batch",
    y = "TRANS% of total",
    fill = "Time"
  )

if (nrow(pct_trans_time_compare) > 0) {
  print(p_pct_trans_t0_t120)
} else {
  message("[2.5 QC] pct_trans_time_compare is empty; no TRANS% (T0 vs T120) plot was produced.")
}

# 6) Within-class combo composition (stacked; should sum to 100% within class)
# Use ONLY the two combos per class (A_to_B/C_to_D within CIS; A_to_D/C_to_B within TRANS)
agg_combo_within_2only <- agg_qc_combo4

cis_combo_long <- agg_combo_within_2only %>%
  select(batch, time_point, Percent_A_to_B_in_Cis, Percent_C_to_D_in_Cis) %>%
  pivot_longer(
    cols = c(Percent_A_to_B_in_Cis, Percent_C_to_D_in_Cis),
    names_to = "Combo",
    values_to = "Percent"
  ) %>%
  mutate(
    Combo = recode(
      Combo,
      Percent_A_to_B_in_Cis = "A_to_B (within CIS)",
      Percent_C_to_D_in_Cis = "C_to_D (within CIS)"
    )
  )

p_cis_combo_comp <- ggplot(cis_combo_long, aes(x = batch, y = Percent, fill = Combo)) +
  geom_col(width = 0.75) +
  geom_text(
    aes(label = if_else(is.na(Percent) | Percent <= 0, NA_character_, paste0(round(Percent, 1), "%"))),
    position = position_stack(vjust = 0.5),
    size = 2.4
  ) +
  facet_wrap(~ time_point) +
  scale_y_continuous(limits = c(0, 100)) +
  theme_bw() +
  labs(
    title = "QC: Within-CIS composition (A_to_B + C_to_D = 100%)",
    x = "Batch",
    y = "% of CIS",
    fill = ""
  )

if (nrow(cis_combo_long) > 0) {
  print(p_cis_combo_comp)
} else {
  message("[2.5 QC] cis_combo_long is empty; no within-CIS composition plot was produced.")
}

trans_combo_long <- agg_combo_within_2only %>%
  select(batch, time_point, Percent_A_to_D_in_Trans, Percent_C_to_B_in_Trans) %>%
  pivot_longer(
    cols = c(Percent_A_to_D_in_Trans, Percent_C_to_B_in_Trans),
    names_to = "Combo",
    values_to = "Percent"
  ) %>%
  mutate(
    Combo = recode(
      Combo,
      Percent_A_to_D_in_Trans = "A_to_D (within TRANS)",
      Percent_C_to_B_in_Trans = "C_to_B (within TRANS)"
    )
  )

p_trans_combo_comp <- ggplot(trans_combo_long, aes(x = batch, y = Percent, fill = Combo)) +
  geom_col(width = 0.75) +
  geom_text(
    aes(label = if_else(is.na(Percent) | Percent <= 0, NA_character_, paste0(round(Percent, 1), "%"))),
    position = position_stack(vjust = 0.5),
    size = 2.4
  ) +
  facet_wrap(~ time_point) +
  scale_y_continuous(limits = c(0, 100)) +
  theme_bw() +
  labs(
    title = "QC: Within-TRANS composition (A_to_D + C_to_B = 100%)",
    x = "Batch",
    y = "% of TRANS",
    fill = ""
  )

if (nrow(trans_combo_long) > 0) {
  print(p_trans_combo_comp)
} else {
  message("[2.5 QC] trans_combo_long is empty; no within-TRANS composition plot was produced.")
}

```

***

## 2.55 NO_CUT baseline growth (media)

Guideline #2: the `NO_CUT` control is used as a baseline readout for how much growth happens in media.

Here we plot spike-scaled `NO_CUT` totals so batches are comparable.

```{r nocut-baseline, message=FALSE, warning=FALSE}
nocut_baseline <- dat %>%
  filter(.data[[COL_ALLELE]] == NOCUT_ALLELE, .data[[COL_COMBO]] %in% combos_4) %>%
  group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT, COL_DSB)))) %>%
  summarise(
    NoCut_Total_SpikeScaled = sum(.data[[COL_COUNT_SPIKE_SCALED]], na.rm = TRUE),
    .groups = "drop"
  )

nocut_baseline %>%
  arrange(batch, DSB, time_point) %>%
  knitr::kable(caption = "NO_CUT baseline totals (spike-scaled) by batch × time_point × DSB")

if (nrow(nocut_baseline) > 0) {
  p_nocut <- ggplot(
    nocut_baseline,
    aes(x = factor(time_point, levels = c(0, 120), labels = c("T0", "T120")),
        y = NoCut_Total_SpikeScaled,
        group = batch,
        color = batch)
  ) +
    geom_line(linewidth = 1.1) +
    geom_point(size = 2.6) +
    facet_wrap(~ DSB, scales = "free_y") +
    theme_bw() +
    labs(
      title = "NO_CUT baseline growth signal (spike-scaled)",
      x = "Time point",
      y = "Spike-scaled NO_CUT counts",
      color = "Batch"
    )
  print(p_nocut)
} else {
  message("[2.55 NO_CUT] nocut_baseline is empty; no NO_CUT baseline plot was produced.")
}
```

***

## 2.6 A/(A+B) normalization plots (CIS/TRANS and INTACT/SSA)

These summaries use the $A/(A+B)$ form (same style as `MD_PD_Analysis.Rmd`):

- $\%\text{CIS} = \frac{\text{CIS}}{\text{CIS}+\text{TRANS}} \times 100$
- $\%\text{TRANS} = \frac{\text{TRANS}}{\text{CIS}+\text{TRANS}} \times 100$
- $\%\text{INTACT} = \frac{\text{INTACT}}{\text{INTACT}+\text{SSA}} \times 100$
- $\%\text{SSA} = \frac{\text{SSA}}{\text{INTACT}+\text{SSA}} \times 100$

```{r ab-normalization-plots, message=FALSE, warning=FALSE}
group_cols_ab <- c(COL_BATCH, COL_TIME_POINT, COL_DSB)

cis_trans_ab <- summarize_cis_trans_ab(
  dat_bio,
  count_col = COL_COUNT_NORM,
  group_cols = group_cols_ab
)

intact_ssa_ab <- summarize_intact_ssa_ab(
  dat_bio,
  count_col = COL_COUNT_NORM,
  group_cols = group_cols_ab
)

ab_joined <- cis_trans_ab %>%
  left_join(intact_ssa_ab, by = group_cols_ab)

ab_joined %>%
  arrange(.data[[COL_BATCH]], .data[[COL_DSB]], .data[[COL_TIME_POINT]]) %>%
  head(20) %>%
  knitr::kable(caption = "Preview: A/(A+B) normalized summaries (first 20 rows)")

# Plot 1: CIS vs TRANS over time (each facet is batch × DSB)
cis_trans_long <- ab_joined %>%
  select(any_of(group_cols_ab), Percent_Cis, Percent_Trans) %>%
  pivot_longer(
    cols = c(Percent_Cis, Percent_Trans),
    names_to = "Class",
    values_to = "Percent"
  ) %>%
  mutate(
    Class = recode(Class, Percent_Cis = "CIS", Percent_Trans = "TRANS"),
    time_point = as.numeric(as.character(.data[[COL_TIME_POINT]]))
  )

if (nrow(cis_trans_long) == 0 || !any(!is.na(cis_trans_long$Percent))) {
  message("[2.6 A/(A+B)] No usable CIS/TRANS% values using count_norm; falling back to spike-scaled counts.")

  cis_trans_ab_fb <- summarize_cis_trans_ab(
    dat_bio,
    count_col = COL_COUNT_SPIKE_SCALED,
    group_cols = group_cols_ab
  )

  cis_trans_long <- cis_trans_ab_fb %>%
    select(any_of(group_cols_ab), Percent_Cis, Percent_Trans) %>%
    pivot_longer(
      cols = c(Percent_Cis, Percent_Trans),
      names_to = "Class",
      values_to = "Percent"
    ) %>%
    mutate(
      Class = recode(Class, Percent_Cis = "CIS", Percent_Trans = "TRANS"),
      time_point = as.numeric(as.character(.data[[COL_TIME_POINT]]))
    )
}

if (nrow(cis_trans_long) > 0) {
  p_cis_trans_time <- ggplot(cis_trans_long, aes(x = time_point, y = Percent, color = Class, group = Class)) +
    geom_line(linewidth = 1.1) +
    geom_point(size = 2.5) +
    facet_grid(.data[[COL_DSB]] ~ .data[[COL_BATCH]], scales = "free_x") +
    scale_y_continuous(limits = c(0, 100)) +
    theme_bw() +
    labs(
      title = "CIS vs TRANS over time (A/(A+B) normalization)",
      x = "Time point",
      y = "% of (CIS + TRANS)",
      color = ""
    )
  print(p_cis_trans_time)
} else {
  message("[2.6 A/(A+B)] cis_trans_long is empty; no CIS/TRANS A/(A+B) plot was produced.")
}

# Plot 2: INTACT vs SSA over time (each facet is batch × DSB)
intact_ssa_long <- ab_joined %>%
  select(any_of(group_cols_ab), Percent_Intact, Percent_SSA) %>%
  pivot_longer(
    cols = c(Percent_Intact, Percent_SSA),
    names_to = "Class",
    values_to = "Percent"
  ) %>%
  mutate(
    Class = recode(Class, Percent_Intact = "INTACT", Percent_SSA = "SSA"),
    time_point = as.numeric(as.character(.data[[COL_TIME_POINT]]))
  )

if (nrow(intact_ssa_long) == 0 || !any(!is.na(intact_ssa_long$Percent))) {
  message("[2.6 A/(A+B)] No usable INTACT/SSA% values using count_norm; falling back to spike-scaled counts.")

  intact_ssa_ab_fb <- summarize_intact_ssa_ab(
    dat_bio,
    count_col = COL_COUNT_SPIKE_SCALED,
    group_cols = group_cols_ab
  )

  intact_ssa_long <- intact_ssa_ab_fb %>%
    select(any_of(group_cols_ab), Percent_Intact, Percent_SSA) %>%
    pivot_longer(
      cols = c(Percent_Intact, Percent_SSA),
      names_to = "Class",
      values_to = "Percent"
    ) %>%
    mutate(
      Class = recode(Class, Percent_Intact = "INTACT", Percent_SSA = "SSA"),
      time_point = as.numeric(as.character(.data[[COL_TIME_POINT]]))
    )
}

if (nrow(intact_ssa_long) > 0) {
  p_intact_ssa_time <- ggplot(intact_ssa_long, aes(x = time_point, y = Percent, color = Class, group = Class)) +
    geom_line(linewidth = 1.1) +
    geom_point(size = 2.5) +
    facet_grid(.data[[COL_DSB]] ~ .data[[COL_BATCH]], scales = "free_x") +
    scale_y_continuous(limits = c(0, 100)) +
    theme_bw() +
    labs(
      title = "INTACT vs SSA over time (A/(A+B) normalization)",
      x = "Time point",
      y = "% of (INTACT + SSA)",
      color = ""
    )
  print(p_intact_ssa_time)
} else {
  message("[2.6 A/(A+B)] intact_ssa_long is empty; no INTACT/SSA A/(A+B) plot was produced.")
}
```

# 3. cis/trans normalization — compute totals and percentages per allele

```{r cis-trans-norm}
my_summarize_cistrans <- function(dat, count_col = "count_spike_scaled"){
  by_allele <- dat %>%
    group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT, COL_DSB, COL_ALLELE)))) %>%
    summarise(
      Cis_Location_Counts   = sum(.data[[count_col]][.data[[COL_CIS_TRANS]] == "CIS"], na.rm = TRUE),
      Trans_Location_Counts = sum(.data[[count_col]][.data[[COL_CIS_TRANS]] == "TRANS"], na.rm = TRUE),
      .groups = "drop"
    )

  totals <- by_allele %>%
    group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT, COL_DSB)))) %>%
    summarise(
      Total_Cis_Location_Counts   = sum(Cis_Location_Counts),
      Total_Trans_Location_Counts = sum(Trans_Location_Counts),
      .groups = "drop"
    )

  by_allele %>%
    left_join(totals, by = c(COL_BATCH, COL_TIME_POINT, COL_DSB)) %>%
    mutate(
      Percent_Location_in_Cis   = if_else(Total_Cis_Location_Counts > 0,
                                         100 * Cis_Location_Counts / Total_Cis_Location_Counts,
                                         NA_real_),
      Percent_Location_in_Trans = if_else(Total_Trans_Location_Counts > 0,
                                         100 * Trans_Location_Counts / Total_Trans_Location_Counts,
                                         NA_real_)
    )
}

dat_norm <- my_summarize_cistrans(dat_bio, count_col = COL_COUNT_SPIKE_SCALED)
dat_norm |> head(10) |> knitr::kable(caption = "Preview: allele-level CIS/TRANS counts and within-class percentages (first 10)")

# Plots (requested): give section 3 a quick visual check.
# To keep the report readable, we plot only the top N alleles per (batch × time_point × DSB)
# ranked by (CIS + TRANS) counts.
top_n_alleles <- 25

dat_norm_top <- dat_norm %>%
  mutate(Total_Allele_Counts = Cis_Location_Counts + Trans_Location_Counts) %>%
  group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT, COL_DSB)))) %>%
  arrange(desc(Total_Allele_Counts)) %>%
  slice_head(n = top_n_alleles) %>%
  ungroup() %>%
  mutate(Facet_Col = paste0("Batch ", .data[[COL_BATCH]], " / T", .data[[COL_TIME_POINT]]))

if (nrow(dat_norm_top) > 0) {
  p_cis_pct_by_allele <- ggplot(dat_norm_top, aes(x = .data[[COL_ALLELE]], y = Percent_Location_in_Cis)) +
    geom_col(width = 0.9, fill = "darkgreen") +
    facet_grid(.data[[COL_DSB]] ~ Facet_Col, scales = "free_x", space = "free_x") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 7)) +
    labs(
      title = paste0("Top ", top_n_alleles, " alleles: Percent within CIS (by batch/time_point)") ,
      x = "Allele",
      y = "Percent of CIS total"
    )
  print(p_cis_pct_by_allele)

  p_trans_pct_by_allele <- ggplot(dat_norm_top, aes(x = .data[[COL_ALLELE]], y = Percent_Location_in_Trans)) +
    geom_col(width = 0.9, fill = "firebrick") +
    facet_grid(.data[[COL_DSB]] ~ Facet_Col, scales = "free_x", space = "free_x") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 7)) +
    labs(
      title = paste0("Top ", top_n_alleles, " alleles: Percent within TRANS (by batch/time_point)"),
      x = "Allele",
      y = "Percent of TRANS total"
    )
  print(p_trans_pct_by_allele)
} else {
  message("[3 CIS/TRANS norm] dat_norm is empty; no allele-level CIS/TRANS plots were produced.")
}
```
***
# 4. Allele frequency (CIS + TRANS)

```{r allele-freq}
cis_combos <- c("A_to_B", "C_to_D")
trans_combos <- c("A_to_D", "C_to_B")

# From section 4 onward, we define:
#   CIS   := A_to_B + C_to_D
#   TRANS := A_to_D + C_to_B
# and ignore any other combos so each group has exactly two CIS counts.

my_summarize_cistrans_by_combo <- function(dat, cis_combos, trans_combos, count_col = COL_COUNT_SPIKE_SCALED){
  by_allele <- dat %>%
    group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT, COL_DSB, COL_ALLELE)))) %>%
    summarise(
      Cis_Location_Counts   = sum(.data[[count_col]][.data[[COL_COMBO]] %in% cis_combos], na.rm = TRUE),
      Trans_Location_Counts = sum(.data[[count_col]][.data[[COL_COMBO]] %in% trans_combos], na.rm = TRUE),
      .groups = "drop"
    )

  totals <- by_allele %>%
    group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT, COL_DSB)))) %>%
    summarise(
      Total_Cis_Location_Counts   = sum(Cis_Location_Counts),
      Total_Trans_Location_Counts = sum(Trans_Location_Counts),
      .groups = "drop"
    )

  by_allele %>%
    left_join(totals, by = c(COL_BATCH, COL_TIME_POINT, COL_DSB)) %>%
    mutate(
      # Group-total counts (restricted to the 4 combos only)
      Total_Group_Counts = Total_Cis_Location_Counts + Total_Trans_Location_Counts,

      # Requested semantics (section 4+):
      #   CIS%  = cis_count / total_count
      #   TRANS% = trans_count / total_count
      # where total_count is the TOTAL within the group (batch × time_point × DSB)
      # and CIS/TRANS are defined by the two combos each.
      # NOTE: These are per-allele *contributions* to the group's total.
      Percent_Cis_of_GroupTotal = if_else(Total_Group_Counts > 0,
                                         100 * Cis_Location_Counts / Total_Group_Counts,
                                         NA_real_),
      Percent_Trans_of_GroupTotal = if_else(Total_Group_Counts > 0,
                                           100 * Trans_Location_Counts / Total_Group_Counts,
                                           NA_real_),

      Percent_Location_in_Cis   = if_else(Total_Cis_Location_Counts > 0,
                                         100 * Cis_Location_Counts / Total_Cis_Location_Counts,
                                         NA_real_),
      Percent_Location_in_Trans = if_else(Total_Trans_Location_Counts > 0,
                                         100 * Trans_Location_Counts / Total_Trans_Location_Counts,
                                         NA_real_)
    )
}

# Filter to only the four combos used downstream (and exclude control alleles)
dat_focus <- dat_bio %>%
  filter(.data[[COL_COMBO]] %in% c(cis_combos, trans_combos))

dat_norm_combo <- my_summarize_cistrans_by_combo(dat_focus, cis_combos, trans_combos, count_col = COL_COUNT_SPIKE_SCALED)

# ---- Group-level summaries using ONLY the four combos (section 4+ semantics) ----
# These are the plots that should behave like:
#   - A_to_B + C_to_D = 100% (within CIS)
#   - A_to_D + C_to_B = 100% (within TRANS)
#   - TRANS% of total is typically lower at T0 than T120 (if biology matches expectation)

dat_group4 <- dat_focus %>%
  # IMPORTANT: do NOT group by DSB here.
  # In this dataset, `DSB` may contain levels like "TRANS" which would split CIS and TRANS
  # across panels and yield misleading 100% bars.
  group_by(across(all_of(c(COL_BATCH, COL_TIME_POINT)))) %>%
  summarise(
    A_to_B = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "A_to_B"], na.rm = TRUE),
    C_to_D = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "C_to_D"], na.rm = TRUE),
    A_to_D = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "A_to_D"], na.rm = TRUE),
    C_to_B = sum(.data[[COL_COUNT_SPIKE_SCALED]][.data[[COL_COMBO]] == "C_to_B"], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Cis_Total = A_to_B + C_to_D,
    Trans_Total = A_to_D + C_to_B,
    Total = Cis_Total + Trans_Total,

    Percent_Cis_of_Total = if_else(Total > 0, 100 * Cis_Total / Total, NA_real_),
    Percent_Trans_of_Total = if_else(Total > 0, 100 * Trans_Total / Total, NA_real_),

    # These should sum to ~100 (within class) when Cis_Total/Trans_Total > 0
    Percent_A_to_B_in_Cis = if_else(Cis_Total > 0, 100 * A_to_B / Cis_Total, NA_real_),
    Percent_C_to_D_in_Cis = if_else(Cis_Total > 0, 100 * C_to_D / Cis_Total, NA_real_),
    Percent_A_to_D_in_Trans = if_else(Trans_Total > 0, 100 * A_to_D / Trans_Total, NA_real_),
    Percent_C_to_B_in_Trans = if_else(Trans_Total > 0, 100 * C_to_B / Trans_Total, NA_real_)
  )

# Share of total CIS/TRANS counts by batch (across ALL batches), separated by time_point.
# This treats the plots as "how much of the total CIS (or TRANS) at this time point comes from each batch".
dat_group4_share <- dat_group4 %>%
  group_by(time_point) %>%
  mutate(
    Total_Cis_AllBatches = sum(Cis_Total, na.rm = TRUE),
    Total_Trans_AllBatches = sum(Trans_Total, na.rm = TRUE),
    Percent_Cis_Share = if_else(Total_Cis_AllBatches > 0, 100 * Cis_Total / Total_Cis_AllBatches, NA_real_),
    Percent_Trans_Share = if_else(Total_Trans_AllBatches > 0, 100 * Trans_Total / Total_Trans_AllBatches, NA_real_)
  )

p_group4_trans_total <- ggplot(dat_group4_share, aes(x = batch, y = Percent_Trans_Share)) +
  geom_col(width = 0.75) +
  geom_text(aes(label = if_else(is.na(Percent_Trans_Share), NA_character_, paste0(round(Percent_Trans_Share, 1), "%"))),
            vjust = -0.25, size = 3.2) +
  facet_wrap(~ time_point) +
  scale_y_continuous(limits = c(0, 110)) +
  theme_bw() +
  labs(
    title = "Share of total TRANS counts by batch (A_to_D + C_to_B only)",
    x = "Batch",
    y = "% of total TRANS (within time point)"
  )

if (nrow(dat_group4_share) > 0) {
  print(p_group4_trans_total)
} else {
  message("[Group4 share] dat_group4_share is empty; no TRANS share plot was produced.")
}

p_group4_cis_total <- ggplot(dat_group4_share, aes(x = batch, y = Percent_Cis_Share)) +
  geom_col(width = 0.75) +
  geom_text(aes(label = if_else(is.na(Percent_Cis_Share), NA_character_, paste0(round(Percent_Cis_Share, 1), "%"))),
            vjust = -0.25, size = 3.2) +
  facet_wrap(~ time_point) +
  scale_y_continuous(limits = c(0, 110)) +
  theme_bw() +
  labs(
    title = "Share of total CIS counts by batch (A_to_B + C_to_D only)",
    x = "Batch",
    y = "% of total CIS (within time point)"
  )

if (nrow(dat_group4_share) > 0) {
  print(p_group4_cis_total)
} else {
  message("[Group4 share] dat_group4_share is empty; no CIS share plot was produced.")
}

# Within-CIS composition: A_to_B vs C_to_D (should sum to 100%)
cis_comp_long4 <- dat_group4 %>%
  select(batch, time_point, Percent_A_to_B_in_Cis, Percent_C_to_D_in_Cis) %>%
  pivot_longer(
    cols = c(Percent_A_to_B_in_Cis, Percent_C_to_D_in_Cis),
    names_to = "Combo",
    values_to = "Percent"
  ) %>%
  mutate(
    Combo = recode(
      Combo,
      Percent_A_to_B_in_Cis = "A_to_B (within CIS)",
      Percent_C_to_D_in_Cis = "C_to_D (within CIS)"
    )
  )

p_cis_comp_2only <- ggplot(cis_comp_long4, aes(x = batch, y = Percent, fill = Combo)) +
  geom_col(width = 0.75) +
  geom_text(
    aes(label = if_else(is.na(Percent) | Percent <= 0, NA_character_, paste0(round(Percent, 1), "%"))),
    position = position_stack(vjust = 0.5),
    size = 2.4
  ) +
  facet_wrap(~ time_point) +
  scale_y_continuous(limits = c(0, 100)) +
  theme_bw() +
  labs(
    title = "Within-CIS composition (A_to_B + C_to_D = 100%)",
    x = "Batch",
    y = "% of CIS",
    fill = ""
  )

if (nrow(cis_comp_long4) > 0) {
  print(p_cis_comp_2only)
} else {
  message("[Group4 within-class] cis_comp_long4 is empty; no within-CIS composition plot was produced.")
}

# Within-TRANS composition: A_to_D vs C_to_B (should sum to 100%)
trans_comp_long4 <- dat_group4 %>%
  select(batch, time_point, Percent_A_to_D_in_Trans, Percent_C_to_B_in_Trans) %>%
  pivot_longer(
    cols = c(Percent_A_to_D_in_Trans, Percent_C_to_B_in_Trans),
    names_to = "Combo",
    values_to = "Percent"
  ) %>%
  mutate(
    Combo = recode(
      Combo,
      Percent_A_to_D_in_Trans = "A_to_D (within TRANS)",
      Percent_C_to_B_in_Trans = "C_to_B (within TRANS)"
    )
  )

p_trans_comp_2only <- ggplot(trans_comp_long4, aes(x = batch, y = Percent, fill = Combo)) +
  geom_col(width = 0.75) +
  geom_text(
    aes(label = if_else(is.na(Percent) | Percent <= 0, NA_character_, paste0(round(Percent, 1), "%"))),
    position = position_stack(vjust = 0.5),
    size = 2.4
  ) +
  facet_wrap(~ time_point) +
  scale_y_continuous(limits = c(0, 100)) +
  theme_bw() +
  labs(
    title = "Within-TRANS composition (A_to_D + C_to_B = 100%)",
    x = "Batch",
    y = "% of TRANS",
    fill = ""
  )

if (nrow(trans_comp_long4) > 0) {
  print(p_trans_comp_2only)
} else {
  message("[Group4 within-class] trans_comp_long4 is empty; no within-TRANS composition plot was produced.")
}

my_summarize_allelefreq <- function(dat){
  by_allele <- dat %>%
    group_by(batch, time_point, DSB, allele) %>%
    summarise(
      Cis_Counts    = sum(count_spike_scaled[combo %in% cis_combos], na.rm = TRUE),
      Trans_Counts  = sum(count_spike_scaled[combo %in% trans_combos], na.rm = TRUE),
      Allele_Total  = Cis_Counts + Trans_Counts,
      .groups = "drop"
    )

  totals <- by_allele %>%
    group_by(batch, time_point, DSB) %>%
    summarise(
      Total_Cis   = sum(Cis_Counts),
      Total_Trans = sum(Trans_Counts),
      Total_All   = Total_Cis + Total_Trans,
      .groups = "drop"
    )

  by_allele %>%
    left_join(totals, by = c("batch", "time_point", "DSB")) %>%
    mutate(
      Allele_Frequency = if_else(Total_All > 0, Allele_Total / Total_All, NA_real_)
    )
}

dat_allele_freq <- my_summarize_allelefreq(dat_focus)
str(dat_allele_freq)

```

## 4.1 Pearson correlation: allele frequency changes by combo (t=0 vs t=120)

This mirrors the correlation/scatter view from `MD_PD_Analysis.Rmd`, adapted to $t=0$ vs $t=120$.

```{r allele-freq-correlation-by-combo, message=FALSE, warning=FALSE}
# Allele frequencies stratified by combo as well
timepoints_compare <- c(0, 120)

dat_allele_freq_combo <- dat_bio %>%
  filter(.data[[COL_COMBO]] %in% combos_4) %>%
  group_by(across(all_of(c(COL_BATCH, COL_DSB, COL_COMBO, COL_TIME_POINT, COL_ALLELE)))) %>%
  summarise(Allele_Counts = sum(.data[[COL_COUNT_NORM]], na.rm = TRUE), .groups = "drop") %>%
  group_by(across(all_of(c(COL_BATCH, COL_DSB, COL_COMBO, COL_TIME_POINT)))) %>%
  mutate(
    Total_Counts = sum(Allele_Counts, na.rm = TRUE),
    Allele_Frequency = if_else(Total_Counts > 0, Allele_Counts / Total_Counts, NA_real_)
  ) %>%
  ungroup() %>%
  mutate(time_point = as.numeric(as.character(.data[[COL_TIME_POINT]]))) %>%
  filter(time_point %in% timepoints_compare)

# Wide format for correlation/scatter
dat_wide_af <- dat_allele_freq_combo %>%
  select(all_of(c(COL_BATCH, COL_DSB, COL_COMBO, COL_ALLELE)), time_point, Allele_Frequency) %>%
  mutate(tp = paste0("t", time_point)) %>%
  select(-time_point) %>%
  tidyr::pivot_wider(names_from = tp, values_from = Allele_Frequency)

# Correlation stats per facet
cor_stats <- dat_wide_af %>%
  group_by(across(all_of(c(COL_BATCH, COL_DSB, COL_COMBO)))) %>%
  summarise(
    n_pairs = sum(!is.na(t0) & !is.na(t120)),
    r = if_else(n_pairs >= 3, cor(t0, t120, use = "complete.obs", method = "pearson"), NA_real_),
    .groups = "drop"
  ) %>%
  mutate(
    label = if_else(
      is.na(r),
      paste0("n=", n_pairs),
      paste0("r=", round(r, 3), "\n", "n=", n_pairs)
    ),
    x = 0.02,
    y = 0.98
  )

plot_cor_by_batch <- function(df_wide, df_stats) {
  batches <- df_wide %>% distinct(.data[[COL_BATCH]]) %>% arrange(.data[[COL_BATCH]]) %>% pull(.data[[COL_BATCH]])
  for (b in batches) {
    dfb <- df_wide %>% filter(.data[[COL_BATCH]] == b)
    if (nrow(dfb) == 0) next

    statsb <- df_stats %>% filter(.data[[COL_BATCH]] == b)

    p <- ggplot(dfb, aes(x = t0, y = t120)) +
      geom_abline(slope = 1, intercept = 0, linewidth = 0.7, linetype = "dashed", color = "grey50") +
      geom_point(alpha = 0.75, size = 1.8) +
      facet_grid(.data[[COL_COMBO]] ~ .data[[COL_DSB]]) +
      geom_text(
        data = statsb,
        aes(x = x, y = y, label = label),
        inherit.aes = FALSE,
        hjust = 0,
        vjust = 1,
        size = 3
      ) +
      scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
      scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
      theme_bw() +
      labs(
        title = paste0("Pearson correlation of allele frequencies (t=0 vs t=120) | Batch: ", b),
        x = "Allele frequency at t=0",
        y = "Allele frequency at t=120"
      )
    print(p)
  }
}

if (nrow(dat_wide_af) > 0) {
  plot_cor_by_batch(dat_wide_af, cor_stats)
}

# Pooled-across-batches view (sum counts then recompute frequencies)
dat_allele_freq_combo_overall <- dat_bio %>%
  filter(.data[[COL_COMBO]] %in% combos_4) %>%
  group_by(across(all_of(c(COL_DSB, COL_COMBO, COL_TIME_POINT, COL_ALLELE)))) %>%
  summarise(Allele_Counts = sum(.data[[COL_COUNT_NORM]], na.rm = TRUE), .groups = "drop") %>%
  group_by(across(all_of(c(COL_DSB, COL_COMBO, COL_TIME_POINT)))) %>%
  mutate(
    Total_Counts = sum(Allele_Counts, na.rm = TRUE),
    Allele_Frequency = if_else(Total_Counts > 0, Allele_Counts / Total_Counts, NA_real_)
  ) %>%
  ungroup() %>%
  mutate(time_point = as.numeric(as.character(.data[[COL_TIME_POINT]]))) %>%
  filter(time_point %in% timepoints_compare)

dat_wide_overall <- dat_allele_freq_combo_overall %>%
  select(all_of(c(COL_DSB, COL_COMBO, COL_ALLELE)), time_point, Allele_Frequency) %>%
  mutate(tp = paste0("t", time_point)) %>%
  select(-time_point) %>%
  tidyr::pivot_wider(names_from = tp, values_from = Allele_Frequency)

cor_stats_overall <- dat_wide_overall %>%
  group_by(across(all_of(c(COL_DSB, COL_COMBO)))) %>%
  summarise(
    n_pairs = sum(!is.na(t0) & !is.na(t120)),
    r = if_else(n_pairs >= 3, cor(t0, t120, use = "complete.obs", method = "pearson"), NA_real_),
    .groups = "drop"
  ) %>%
  mutate(
    label = if_else(
      is.na(r),
      paste0("n=", n_pairs),
      paste0("r=", round(r, 3), "\n", "n=", n_pairs)
    ),
    x = 0.02,
    y = 0.98
  )

if (nrow(dat_wide_overall) > 0) {
  p_overall <- ggplot(dat_wide_overall, aes(x = t0, y = t120)) +
    geom_abline(slope = 1, intercept = 0, linewidth = 0.7, linetype = "dashed", color = "grey50") +
    geom_point(alpha = 0.75, size = 1.8) +
    facet_grid(.data[[COL_COMBO]] ~ .data[[COL_DSB]]) +
    geom_text(
      data = cor_stats_overall,
      aes(x = x, y = y, label = label),
      inherit.aes = FALSE,
      hjust = 0,
      vjust = 1,
      size = 3
    ) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
    theme_bw() +
    labs(
      title = "Pearson correlation of allele frequencies (t=0 vs t=120) pooled across batches",
      x = "Allele frequency at t=0",
      y = "Allele frequency at t=120"
    )
  print(p_overall)
}
```

---
# 5. Fold change calculations (120 / 0)

```{r fold-change}
library(tidyr)

# Fold change helper.
# We compute FC per allele/location as (T120 / T0) on COUNTS.
# If both numerator and denominator are 0, the fold change is undefined -> NA.
eps <- 1e-6
fc_ratio <- function(num, den, eps = 1e-6) {
  ifelse(is.na(num) | is.na(den), NA_real_,
         ifelse(num == 0 & den == 0, NA_real_, (num + eps) / (den + eps)))
}

dat_fc_cis <- dat_norm_combo %>%
  filter(time_point %in% c(0, 120)) %>%
  select(batch, time_point, DSB, allele, Cis_Location_Counts) %>%
  pivot_wider(names_from = time_point, values_from = Cis_Location_Counts, values_fill = 0) %>%
  mutate(
    FoldChange_Cis_120_vs_0 = fc_ratio(`120`, `0`, eps = eps),
    Log2FC_Cis_120_vs_0 = log2(FoldChange_Cis_120_vs_0)
  )

dat_fc_trans <- dat_norm_combo %>%
  filter(time_point %in% c(0, 120)) %>%
  select(batch, time_point, DSB, allele, Trans_Location_Counts) %>%
  pivot_wider(names_from = time_point, values_from = Trans_Location_Counts, values_fill = 0) %>%
  mutate(
    FoldChange_Trans_120_vs_0 = fc_ratio(`120`, `0`, eps = eps),
    Log2FC_Trans_120_vs_0 = log2(FoldChange_Trans_120_vs_0)
  )

```
***
# 6. Correlation: log2 Fold Change vs Allele Frequency

```{r cor-allelefreq}
library(tidyr)

if (!exists("eps", inherits = TRUE)) eps <- 1e-6
if (!exists("fc_ratio", inherits = TRUE)) {
  fc_ratio <- function(num, den, eps = 1e-6) {
    ifelse(is.na(num) | is.na(den), NA_real_,
           ifelse(num == 0 & den == 0, NA_real_, (num + eps) / (den + eps)))
  }
}

dat_wide <- dat_norm_combo %>%
  filter(time_point %in% c(0, 120)) %>%
  select(batch, DSB, allele, time_point, Cis_Location_Counts, Trans_Location_Counts) %>%
  pivot_wider(names_from = time_point, values_from = c(Cis_Location_Counts, Trans_Location_Counts), values_fill = 0) %>%
  mutate(
    log2FC_CIS   = log2(fc_ratio(Cis_Location_Counts_120, Cis_Location_Counts_0, eps = eps)),
    log2FC_TRANS = log2(fc_ratio(Trans_Location_Counts_120, Trans_Location_Counts_0, eps = eps))
  )

dat_fc_af <- dat_wide %>%
  inner_join(
    dat_allele_freq %>% filter(time_point == 120) %>% select(batch, DSB, allele, Allele_Frequency),
    by = c("batch", "DSB", "allele")
  ) %>%
  filter(!is.na(Allele_Frequency) & Allele_Frequency > 0)

cor_summary <- dat_fc_af %>%
  group_by(batch, DSB) %>%
  summarise(
    cor_CIS_AF   = ifelse(n() >= 2, cor(log2FC_CIS, Allele_Frequency), NA),
    cor_TRANS_AF = ifelse(n() >= 2, cor(log2FC_TRANS, Allele_Frequency), NA),
    n_obs = n(),
    .groups = "drop"
  )

knitr::kable(cor_summary, caption = "Correlation summary: Pearson r between log2FC and allele frequency (by batch × DSB)")

```
***
# 7a. CIS percentage bar plot 

```{r CIS-bar-plot}
# CIS% contribution (within CIS only):
#   for each group (batch × time_point × DSB), we compute each allele's share of TOTAL CIS,
#   using ONLY the CIS combos (A_to_B + C_to_D).
df_cis_dist <- dat_norm_combo %>%
  filter(time_point %in% c(0, 120)) %>%
  select(batch, time_point, DSB, allele, Percent_Location_in_Cis)

plot_cis_contrib_by_batch <- function(df_cis_dist) {
  df_cis_dist <- df_cis_dist %>%
    mutate(
      time_point = factor(time_point, levels = c(0, 120), labels = c("T0", "T120")),
      DSB = factor(DSB, levels = c("DSB1", "DSB2", "TRANS"))
    )

  batches <- df_cis_dist %>% distinct(batch) %>% arrange(batch) %>% pull(batch)
  for (b in batches) {
    df_plot <- df_cis_dist %>% filter(batch == b)

    if (nrow(df_plot) == 0 || all(is.na(df_plot$Percent_Location_in_Cis))) next

    p <- ggplot(df_plot, aes(x = allele, y = Percent_Location_in_Cis, fill = DSB)) +
      geom_col(position = position_dodge(width = 0.9), width = 0.85) +
      geom_text(
        aes(label = if_else(is.na(Percent_Location_in_Cis), NA_character_, paste0(round(Percent_Location_in_Cis, 1), "%"))),
        position = position_dodge(width = 0.9),
        vjust = -0.25,
        size = 3.0,
        angle = 90
      ) +
      facet_wrap(~ time_point, scales = "free_x") +
      scale_y_continuous(limits = c(0, 110)) +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5, size = 10)) +
      labs(
        title = paste0("CIS% contribution by allele (within CIS only) | Batch: ", b),
        x = "Allele",
        y = "CIS% of CIS total (within group)",
        fill = "DSB"
      )

    print(p)
  }
}

plot_cis_contrib_by_batch(df_cis_dist)

```
# 7b. TRANS percentage bar plot 

```{r trans-bar-plot}
# TRANS% contribution (within TRANS only):
#   for each group (batch × time_point × DSB), we compute each allele's share of TOTAL TRANS,
#   using ONLY the TRANS combos (A_to_D + C_to_B).

df_trans_dist <- dat_norm_combo %>%
  filter(time_point %in% c(0, 120)) %>%
  select(batch, time_point, DSB, allele, Percent_Location_in_Trans)

plot_trans_contrib_by_batch <- function(df_trans_dist) {
  df_trans_dist <- df_trans_dist %>%
    mutate(
      time_point = factor(time_point, levels = c(0, 120), labels = c("T0", "T120")),
      DSB = factor(DSB, levels = c("DSB1", "DSB2", "TRANS"))
    )

  batches <- df_trans_dist %>% distinct(batch) %>% arrange(batch) %>% pull(batch)
  for (b in batches) {
    df_plot <- df_trans_dist %>% filter(batch == b)

    if (nrow(df_plot) == 0 || all(is.na(df_plot$Percent_Location_in_Trans))) next

    p <- ggplot(df_plot, aes(x = allele, y = Percent_Location_in_Trans, fill = DSB)) +
      geom_col(position = position_dodge(width = 0.9), width = 0.85) +
      geom_text(
        aes(label = if_else(is.na(Percent_Location_in_Trans), NA_character_, paste0(round(Percent_Location_in_Trans, 1), "%"))),
        position = position_dodge(width = 0.9),
        vjust = -0.25,
        size = 3.0,
        angle = 90
      ) +
      facet_wrap(~ time_point, scales = "free_x") +
      scale_y_continuous(limits = c(0, 110)) +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5, size = 10)) +
      labs(
        title = paste0("TRANS% contribution by allele (within TRANS only) | Batch: ", b),
        x = "Allele",
        y = "TRANS% of TRANS total (within group)",
        fill = "DSB"
      )

    print(p)
  }
}

plot_trans_contrib_by_batch(df_trans_dist)

# Optional: TRANS distribution broken down by combo (A_to_D vs C_to_B)
# Requested view: T0 and T120 on the SAME graph with different-colored bars.
plot_trans_percent_by_combo <- function(dat, combo_name) {
  combo_map <- c(
    "A to D" = "A_to_D",
    "A_to_D" = "A_to_D",
    "B to C" = "C_to_B",
    "B_to_C" = "C_to_B",
    "C to B" = "C_to_B",
    "C_to_B" = "C_to_B"
  )
  if (!is.null(combo_map[[combo_name]])) {
    combo_name <- combo_map[[combo_name]]
  }

  df_plot <- dat %>%
    filter(combo == combo_name, time_point %in% c(0, 120)) %>%
    group_by(batch, time_point, DSB, allele) %>%
    summarise(
      Trans_Counts = sum(count_spike_scaled, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    group_by(batch, time_point, DSB) %>%
    mutate(
      Total_Trans = sum(Trans_Counts),
      Percent_Trans = if_else(Total_Trans > 0, 100 * Trans_Counts / Total_Trans, NA_real_)
    )

  if (nrow(df_plot) == 0 || all(is.na(df_plot$Percent_Trans))) return(NULL)

  ggplot(
      df_plot,
      aes(
        x = allele,
        y = Percent_Trans,
        fill = factor(time_point, levels = c(0, 120), labels = c("T0", "T120"))
      )
    ) +
      geom_col(position = position_dodge(width = 0.9), width = 0.85) +
      geom_text(
        aes(label = if_else(is.na(Percent_Trans), NA_character_, paste0(round(Percent_Trans, 1), "%"))),
        position = position_dodge(width = 0.9),
        vjust = -0.25,
        size = 3.0,
        angle = 90
      ) +
      facet_grid(batch + DSB ~ ., scales = "free_x") +
      scale_y_continuous(limits = c(0, 110)) +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5, size = 10)) +
      labs(
        title = paste("Percent of", combo_name, "counts by allele (within combo; T0 vs T120)"),
        x = "Allele",
        y = "% within combo (within group)",
        fill = "Time"
      )
}

p_trans_ad <- plot_trans_percent_by_combo(dat_focus, "A_to_D")
if (!is.null(p_trans_ad)) print(p_trans_ad)

p_trans_cb <- plot_trans_percent_by_combo(dat_focus, "C_to_B")
if (!is.null(p_trans_cb)) print(p_trans_cb)

```
***
# 8. Fold Change bar plot 

```{r foldchange-bar-plot}
plot_foldchange_cis_by_batch <- function(dat_fc_cis) {
  batches <- dat_fc_cis %>% distinct(batch) %>% arrange(batch) %>% pull(batch)
  for (b in batches) {
    df_plot <- dat_fc_cis %>% filter(batch == b)

    if (nrow(df_plot) == 0 || all(is.na(df_plot$FoldChange_Cis_120_vs_0))) next
    p <- ggplot(df_plot, aes(x = allele, y = FoldChange_Cis_120_vs_0, fill = DSB)) +
      geom_col(position = position_dodge(width = 0.9), width = 0.85) +
      geom_text(
        aes(label = if_else(is.na(FoldChange_Cis_120_vs_0), NA_character_, sprintf("%.3f", FoldChange_Cis_120_vs_0))),
        position = position_dodge(width = 0.9),
        vjust = -0.25,
        size = 3.0,
        angle = 90
      ) +
      scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
      theme_bw(base_size = 14) +
      theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5, size = 10)) +
      labs(
        title = paste0("Fold change (120/0) in CIS counts by allele | Batch: ", b),
        x = "Allele",
        y = "Fold change of CIS counts (120/0)",
        fill = "DSB"
      )
    print(p)
  }
}

plot_foldchange_trans_by_batch <- function(dat_fc_trans) {
  batches <- dat_fc_trans %>% distinct(batch) %>% arrange(batch) %>% pull(batch)
  for (b in batches) {
    df_plot <- dat_fc_trans %>% filter(batch == b)

    if (nrow(df_plot) == 0 || all(is.na(df_plot$FoldChange_Trans_120_vs_0))) next
    p <- ggplot(df_plot, aes(x = allele, y = FoldChange_Trans_120_vs_0, fill = DSB)) +
      geom_col(position = position_dodge(width = 0.9), width = 0.85) +
      geom_text(
        aes(label = if_else(is.na(FoldChange_Trans_120_vs_0), NA_character_, sprintf("%.3f", FoldChange_Trans_120_vs_0))),
        position = position_dodge(width = 0.9),
        vjust = -0.25,
        size = 3.0,
        angle = 90
      ) +
      scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
      theme_bw(base_size = 14) +
      theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5, size = 10)) +
      labs(
        title = paste0("Fold change (120/0) in TRANS counts by allele | Batch: ", b),
        x = "Allele",
        y = "Fold change of TRANS counts (120/0)",
        fill = "DSB"
      )
    print(p)
  }
}

plot_allele_frequency_by_batch <- function(dat_allele_freq) {
  batches <- dat_allele_freq %>% distinct(batch) %>% arrange(batch) %>% pull(batch)
  for (b in batches) {
    df_plot <- dat_allele_freq %>% filter(batch == b)

    if (nrow(df_plot) == 0 || all(is.na(df_plot$Allele_Frequency))) next
    p <- ggplot(df_plot, aes(x = allele, y = Allele_Frequency, fill = DSB)) +
      geom_col(position = position_dodge(width = 0.9), width = 0.85) +
      geom_text(
        aes(label = if_else(is.na(Allele_Frequency), NA_character_, sprintf("%.3f", Allele_Frequency))),
        position = position_dodge(width = 0.9),
        vjust = -0.25,
        size = 3.0,
        angle = 90
      ) +
      scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
      facet_wrap(~ time_point, scales = "free_x") +
      theme_bw(base_size = 14) +
      theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5, size = 10)) +
      labs(
        title = paste0("Allele Frequency (CIS + TRANS) | Batch: ", b),
        x = "Allele",
        y = "Allele Frequency",
        fill = "DSB"
      )
    print(p)
  }
}

# Generate updated plots
plot_foldchange_cis_by_batch(dat_fc_cis)
plot_foldchange_trans_by_batch(dat_fc_trans)
plot_allele_frequency_by_batch(dat_allele_freq)


```
***
# 9. Correlation scatter plots (log2FC vs Allele Frequency)
```{r cor-allele-log}
use_repel <- requireNamespace("ggrepel", quietly = TRUE)

plot_correlation_cis <- function(dat_fc_af, batch_name, dsb_name) {
  df_plot <- dat_fc_af %>% filter(batch == batch_name, DSB == dsb_name)
  if (nrow(df_plot) >= 2) {
    p <- ggplot(df_plot, aes(x = Allele_Frequency, y = log2FC_CIS, label = allele)) +
      geom_point(size = 3, alpha = 0.8, color = "darkgreen") +
      geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
      geom_smooth(method = "lm", se = FALSE, color = "red") +
      theme_bw() +
      labs(
        title = paste0("Log2FC CIS vs Allele Freq | Batch: ", batch_name, " | DSB: ", dsb_name),
        x = "Allele Frequency", y = "log2FC CIS"
      )

    if (use_repel) {
      p <- p + ggrepel::geom_text_repel(size = 3, max.overlaps = 20)
    } else {
      p <- p + geom_text(size = 3, check_overlap = TRUE, vjust = -0.25)
    }

    p
  }
}

plot_correlation_trans <- function(dat_fc_af, batch_name, dsb_name) {
  df_plot <- dat_fc_af %>% filter(batch == batch_name, DSB == dsb_name)
  if (nrow(df_plot) >= 2) {
    p <- ggplot(df_plot, aes(x = Allele_Frequency, y = log2FC_TRANS, label = allele)) +
      geom_point(size = 3, alpha = 0.8, color = "steelblue") +
      geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
      geom_smooth(method = "lm", se = FALSE, color = "red") +
      theme_bw() +
      labs(
        title = paste0("Log2FC TRANS vs Allele Freq | Batch: ", batch_name, " | DSB: ", dsb_name),
        x = "Allele Frequency", y = "log2FC TRANS"
      )

    if (use_repel) {
      p <- p + ggrepel::geom_text_repel(size = 3, max.overlaps = 20)
    } else {
      p <- p + geom_text(size = 3, check_overlap = TRUE, vjust = -0.25)
    }

    p
  }
}

# Generate plots per batch × DSB (no pooling)
plot_keys <- dat_fc_af %>% distinct(batch, DSB) %>% arrange(batch, DSB)
for (i in seq_len(nrow(plot_keys))) {
  b <- plot_keys$batch[[i]]
  d <- plot_keys$DSB[[i]]
  p_cis <- plot_correlation_cis(dat_fc_af, b, d)
  p_trans <- plot_correlation_trans(dat_fc_af, b, d)
  if (!is.null(p_cis)) print(p_cis)
  if (!is.null(p_trans)) print(p_trans)
}
```
